import streamlit as st
from PIL import Image
import matplotlib.pyplot as plt



def show_page(params):
    """Returns `True` if the user had the correct password."""

    col1, col2, col3 = st.columns([1,1,1])   
    col2.header('Explanation about why it was developed and how it works')  
    col2.subheader('')
    col2.subheader('Scraping details of jobs and developing a personal filter for better matches')

    col2.subheader("Context:")
    col2.text("Given the significant number of jobs on the LinkedIn site, it isn't easy to do an accurate search.")
    col2.text("The search needs to be more precise, even with the site's filters.")
    col2.text("With this, we captured this data to develop more precise ways of searching for the perfect match job.")

    col2.subheader("Solution:")
    col2.text("Scrap all job data on the LinkedIn site automatically.")
    col2.text("After collecting the data, use a filter strategy to optimize the search.")

    col2.subheader("Challenge:")
    col2.text("There is not a single page with all opportunities.")
    col2.text("The generation of new content is automatically generated by scrolling through JAVASCRIPT.")
    col2.text("JAVASCRIPT generates the detailed content of each job after clicking on each unique opportunity.")

    col2.subheader("Strategy adopted and solution architecture:")
    col2.text("It was possible to capture the API link triggered with the mouse scroll.")
    col2.text("This avoided the need for more robust technologies, such as selenium.")
    col2.text("With this, it was possible to go through all the job pages that contained the generic information of each job.")
    col2.text("With the captured generic information, it was possible to capture the unique ID of each job.")
    col2.text("With the unique ID of each job, it was possible to access a detail page from where all the project information was extracted.")

    col2.header('Architecture and operation flowchart')  
    # Load the image
    image = Image.open("images/01.jpg")

    # Display the image using Streamlit
    col2.image(image, caption='GCP architecture', use_column_width=True)

    col2.text("The arctechture choiced was google GCP.")
    col2.text("For processing the scrapy library and all Python processes and treatment, the google cloud function, a serverless solution, was used to run the pipeline.")
    col2.text("The cloud function was started and scheduled by workflows programmed to start the scrapy pipeline once daily.")
    col2.text("Cloud function was set to save the scraped data in the big query database already cleaned.")
    col2.text("The app used here for deployment was streamlit, which access big query to get the data and show it to the final user.")
    col2.text("The final user can access all the data scraped and apply several filters to improve your search job.")
    col2.text("A technique of spacing requests every 10 seconds was used to avoid the necessity to use proxy services.")
    col2.text("In this way, the total daily processing time cost generated a lower price than hiring a proxy provider service.")
    





